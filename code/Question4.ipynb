{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from gensim import corpora\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import pyLDAvis.gensim_models\n",
    "import pyLDAvis\n",
    "\n",
    "path1 =  r\"D:\\MCM\\COCA60000.xlsx\"#path1是短期的文件路径\n",
    "df= pd.read_excel(path1,\"word frequency list 60000 Engli\")\n",
    "df = df.dropna()\n",
    "words = df.iloc[:,0]\n",
    "print(words)\n",
    "# words = np.array(df.iloc[:,4])\n",
    "# print(words)\n",
    "\n",
    "stopwords = ['this','i','me','my','myself','we','our','ours','ourselves','you',\n",
    "\"you're\",\"you've\",\"'you'll\",\"you'd\",'yours','yourself','yourselves','he',\n",
    "'he','his','him','himself','she',\"she's\",'her','herself','it',\"it's\",'its'\n",
    "'itself','their','them','they','theirs','themselves','what','which','who','whom'\n",
    "'this','that',\"that'll\",'these','those','am','is','the','are','was','were','be','been'\n",
    "'being','have','has','had','having','do',\"does\",'did','doing','a','a','and','but',\n",
    "'if','or','because','as','until','while','of','at','by','for','with','about','against'\n",
    "'between','into','through','during','before','after',\"above\",'below','to','from',\n",
    "'up',\"down\",'in','out','on','off','over','under','again','further','then','once',\n",
    "'here',\"there\",'when','where','why','how','all','any','both','each','few','more','most',\n",
    "'other','some','such',\"no\",'nor','only','own','same','so','than',\"too\",'very','s','t',\n",
    "'can','will','not','just',\"don'\",\"don't\",\"should\", \"should've\",\"now\",'d','ll','m','re',\n",
    "'ve','ain','aren',\"aren't\",'couldn',\"couldn't\",'didn',\"didn't\", 'doesn', \"doesn't\", 'hadn',\n",
    "\"hadn't\",'hasn',\"hasn't\",\"hasin't\",\"haven't\",'haven','isn',\"isn't\",'ma','mightn',\"mightn't\",\n",
    "\"mustn\",\"mustn't\",\"weren\",\"weren't\",\"won\",\"won't\",\"needn\",\"needn't\",\"shan\",\"wouldn\",\"wouldn't\",'must',\n",
    "'one','two','three','four','five','six','seven','eight','nine','ten','also','always','br','<br/>'\n",
    ",'etc','didnt','isnt','This','That','Those','These','His','Her','My','Our','Your','Their','It'\n",
    "'Will','Dont',\"Don't\",'Is','Isnt','Didnt',\"Didn't\",'Having','Do','Does','Did','good'\n",
    ",'great','works','work','worked','problem','open','small','excellent','perfect','nice',\n",
    "'little','love','loves','loved','like','liked','likes','exactly','easy','well','wall','new','old','enjoy',\n",
    "'looks','look','buy','ge','un','An','fine','much','really','anyone','across','ask','aside','asked'\n",
    "'another','THIS','asks','anywhere','anyhow','around','big','begins','began','begun','beside','besides',\n",
    "'during','early','eg','everybody','everywhere','forth','hence','hardly','immediate','immediately',\n",
    "'instead','interested','interesting','interest','knows','knew','I','later','let',\"let's\",'line',\n",
    "'latest','likely','long','latterly','make','makes','made','mainly','mean','most','mostly','mr','mrs',\n",
    "'must','namely','nd','nb','next','none','nontheless','noone','nor','number','numbers','obtain','one',\n",
    "'overall','order','own','part','parted','particular','particularly','poor','poorly','plus','point','possible'\n",
    ",'possiblity','possibly','provides','provided','put','presented','presents','readily','research','refs','relatively',\n",
    "'room','right','rooms','run','regardless','regarding','saw','saying','said','say','second','section','self',\n",
    "'same','seem','seemed','seems','secondly','selves','sensible','sent','side','significantly','similar',\n",
    "'smaller','similarly','similar','so','somehow','someone','somethan','something','somewhat','sorry','soon',\n",
    "'specify','specifying','state','states','strongly','sub','substantly','success','succeed','succeeded',\n",
    "'successfully','sup','sure','taken','thanks','thank','tends','tend','tended','taking','take','takes','thats',\n",
    "'third','thorough','thoughts','thousand','throng','through','though','throughout','thus','tip','thru','today',\n",
    "'together','too','truly','twice','trying','tries','tried','ts','turn','turned','upon','ups','up','unless',\n",
    "'unlike','unto','ups','uses','used','usefully','usefulness','uses','usefully','usually','v','values','vs','vols',\n",
    "'vol','via','various','want','wanting','wants','way','welcome','whim','whereby','whither','whereuopn','whereafter',\n",
    "'within','whithout','words','word','working','www','x','y','years','yes','yet','you','young','younger','yourz',\n",
    "'zero','zt','zz','THis','THIs','tHis','thIS','thiS','WOULD','Would','Problems','Samsung','samsung','Came','CAME','came'\n",
    ",'problem','problemz','perfectly','Perfectly','less','Less','money','Money','microwave','months','got','lot','everthing',\n",
    "'installed','use','less']#创建停用词表\n",
    "\n",
    "text1 = []\n",
    "words_no_punc = []\n",
    "\n",
    "\n",
    "for w in words:\n",
    "    print(w)\n",
    "    if w.isalpha() and w.lower() not in stopwords:\n",
    "        words_no_punc.append(w.lower())#去掉其中的标点\n",
    "        text1.append(words_no_punc)\n",
    "\n",
    "\n",
    "dictionary = corpora.Dictionary(text1)\n",
    "# 得到文档-单词矩阵 （直接利用统计词频得到特征）\n",
    "\n",
    "texts = [dictionary.doc2bow(textt) for textt in text1]\n",
    "# 将dictionary转化为一个词袋，得到文档-单词矩阵\n",
    "\n",
    "num_topics=8\n",
    "#lda = models.ldamodel.LdaModel(corpus=texts, id2word=dictionary, num_topics=num_topics)\n",
    "texts_tf_idf = models.TfidfModel(texts)[texts]\n",
    "#lda = models.ldamodel.LdaModel(corpus=texts_tf_idf, id2word=dictionary, num_topics=num_topics)\n",
    "\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "ldamodel = Lda(texts_tf_idf, num_topics=2, id2word = dictionary, passes=50)\n",
    "\n",
    "d = pyLDAvis.gensim_models.prepare(ldamodel, texts, dictionary)\n",
    "pyLDAvis.show(d)\n",
    "pyLDAvis.save_html(d, 'lda_pass10.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "\n",
    "path = r\"D:\\MCM\\data sigma.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "df1 = df[df['1 try']>1]\n",
    "df2 = df[df['1 try']<=1]\n",
    "\n",
    "df1 = df1.iloc[:,14:18]\n",
    "df2 = df2.iloc[:,14:18]\n",
    "\n",
    "col_means1 = df1.mean()\n",
    "col_means2 = df2.mean()\n",
    "\n",
    "x = ['average word letter','average word class','average word frequency','average letter repeat']\n",
    "\n",
    "plt.rcParams['font.family']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus']=False\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']#正常显示标签\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "# 设置柱状图参数\n",
    "width = 0.35\n",
    "\n",
    "# 绘制第一组数据\n",
    "x = np.arange(len(x))\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, col_means1, width, label='Data 1')\n",
    "\n",
    "# 绘制第二组数据\n",
    "rects2 = ax.bar(x + width/2, col_means2, width, label='Data 2')\n",
    "\n",
    "# 设置图例和横纵坐标轴标签\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(x)\n",
    "ax.legend()\n",
    "#ax.set_xlabel('X Label')\n",
    "#ax.set_ylabel('Y Label')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import lagrange\n",
    "\n",
    "path = r\"D:\\MCM\\data sigma.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "y = df['word_difficult']\n",
    "n = len(y)\n",
    "x = np.arange(n)\n",
    "\n",
    "# 多项式拟合\n",
    "poly_fit = np.polyfit(x, y, deg=3)\n",
    "poly_func = np.poly1d(poly_fit)\n",
    "y_poly = poly_func(x)\n",
    "\n",
    "# 样条插值\n",
    "interp_func = interp1d(x, y, 'cubic')\n",
    "y_interp = interp_func(x)\n",
    "\n",
    "# 绘图\n",
    "plt.subplots(figsize=(100, 5))\n",
    "plt.plot(x, y, 'o', label='data')\n",
    "plt.plot(x, y_poly, label='poly fit')\n",
    "plt.plot(x, y_interp, label='spline')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
